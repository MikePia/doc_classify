{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import fitz  # PyMuPDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='document_processing_errors.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(path):\n",
    "    try:\n",
    "        doc = fitz.open(path)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            try:\n",
    "                text += page.get_text()\n",
    "            except Exception as page_error:\n",
    "                print(f\"Error extracting text from page in {path}: {page_error}\")\n",
    "                continue\n",
    "                # Optionally, continue to the next page or log the error\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        logging.info(f\"Error processing file {path}: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use one or the othere here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Or a larger model as needed\n",
    "\n",
    "def clean_and_tokenize(text, chunk_size=1000000):\n",
    "    \"\"\"\n",
    "    Tokenizes the text using SpaCy, handling long texts by processing in chunks.\n",
    "    \n",
    "    :param text: The text to be tokenized.\n",
    "    :param chunk_size: Maximum chunk size in characters.\n",
    "    :return: A string of the lemmatized tokens.\n",
    "    \"\"\"\n",
    "    # Check if the text length exceeds the chunk size\n",
    "    if len(text) > chunk_size:\n",
    "        # Initialize an empty list to store tokens from all chunks\n",
    "        tokens_all_chunks = []\n",
    "        \n",
    "        # Process the text in chunks\n",
    "        for start in range(0, len(text), chunk_size):\n",
    "            end = start + chunk_size\n",
    "            # Extract a chunk of text\n",
    "            chunk = text[start:end]\n",
    "            # Process the chunk\n",
    "            doc = nlp(chunk)\n",
    "            # Extract tokens, lemmatize, and filter as before\n",
    "            tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "            tokens_all_chunks.extend(tokens)\n",
    "        \n",
    "        # Combine tokens from all chunks and return\n",
    "        return \" \".join(tokens_all_chunks)\n",
    "    else:\n",
    "        # If text does not exceed the chunk size, process as before\n",
    "        doc = nlp(text)\n",
    "        tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "# Example of how to apply this function to your DataFrame\n",
    "# df['tokenized_text'] = df['cleaned_text'].apply(clean_and_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize_chunk(chunk):\n",
    "    \"\"\"\n",
    "    Tokenizes a single chunk of text.\n",
    "    \"\"\"\n",
    "    doc = nlp(chunk)\n",
    "    return [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "def batch_tokenize_texts(texts, batch_size=1000, chunk_size=1000000):\n",
    "    \"\"\"\n",
    "    Tokenize a list of texts in batches, handling long texts by processing in chunks.\n",
    "    \n",
    "    :param texts: The list of texts to be tokenized.\n",
    "    :param batch_size: Number of texts to process in a single batch.\n",
    "    :param chunk_size: Maximum chunk size in characters for each text.\n",
    "    :return: A list of lists, where each sublist contains the tokens of a text.\n",
    "    \"\"\"\n",
    "    processed_texts = []\n",
    "    for text in texts:\n",
    "        # If the text is longer than chunk_size, split it into chunks\n",
    "        if len(text) > chunk_size:\n",
    "            tokens_all_chunks = []\n",
    "            for start in range(0, len(text), chunk_size):\n",
    "                end = start + chunk_size\n",
    "                chunk = text[start:end]\n",
    "                # Tokenize the chunk and extend the list of tokens\n",
    "                tokens_all_chunks.extend(clean_and_tokenize_chunk(chunk))\n",
    "            processed_texts.append(tokens_all_chunks)\n",
    "        else:\n",
    "            # For texts that don't exceed the chunk size, process as usual\n",
    "            tokens = clean_and_tokenize_chunk(text)\n",
    "            processed_texts.append(tokens)\n",
    "    \n",
    "    return processed_texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Extraction\n",
    "- **Combine keyword-matching and TF-IDF**\n",
    "- **TF-IDF Vectorization:** Use Scikit-learn's TfidfVectorizer to convert the cleaned text documents into a matrix of TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for keyword presence\n",
    "def check_keywords(text, keyword_list):\n",
    "    text = text.lower()\n",
    "    return int(any(keyword in text for keyword in keyword_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alternate code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def check_keywords_alternate(text, keyword_list):\n",
    "    text = text.lower()\n",
    "    # Create a pattern that matches whole words only, for all keywords\n",
    "    pattern = r'\\b(' + '|'.join([re.escape(keyword) for keyword in keyword_list]) + r')\\b'\n",
    "    return int(bool(re.search(pattern, text)))\n",
    "\n",
    "def safety_not_run_thing():\n",
    "    # Convert keywords to lowercase for case-insensitive matching\n",
    "    keywords = {category: [keyword.lower() for keyword in keyword_list] for category, keyword_list in keywords.items()}\n",
    "\n",
    "    # Assuming 'tokenized_text' contains space-separated tokens, it should work well with the modified check_keywords function.\n",
    "    # Just ensure 'tokenized_text' is a string; if it's a list of tokens, you might need to join them first:\n",
    "    # df['tokenized_text_str'] = df['tokenized_text'].apply(' '.join)\n",
    "\n",
    "    for category, keyword_list in keywords.items():\n",
    "        df[category + '_keyword'] = df['tokenized_text'].apply(check_keywords, args=(keyword_list,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tfidf_keyword(df):\n",
    "    # Step 2: TF-IDF Calculation\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)  # Adjust number of features as needed\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['tokenized_text'])\n",
    "\n",
    "    # Step 3. Combine keyword and tfidf features into a single matrix    \n",
    "    # Convert binary keyword matches to a matrix\n",
    "    keyword_features = df[[col for col in df.columns if '_keyword' in col]].to_numpy()\n",
    "    # Combine TF-IDF features with keyword binary indicators\n",
    "    combined_features = np.hstack((tfidf_matrix.toarray(), keyword_features))\n",
    "\n",
    "    # Now `combined_features` is ready for model training, and should be aligned with your labels.\n",
    "    return combined_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training the Classification Model\n",
    "\n",
    "### Next Steps (not-implemented)\n",
    "\n",
    "    Train Your Model: Use the combined_features matrix along with your labels to train and evaluate your classification model.\n",
    "    Evaluation and Refinement: Assess the model's performance and adjust your keyword lists, TF-IDF parameters, or model choice as needed.\n",
    "\n",
    "This approach leverages both the specificity of keyword matching and the nuanced importance scoring of TF-IDF, providing a rich set of features for document classification.\n",
    "\n",
    "- **Splitting Data:** Use your 1000 classified documents as training data. Ensure you have a balanced dataset for the three categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "    # Split the data - 70% for training, 30% for testing; adjust ratios as you see fit\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Model Selection and Training:** Given the textual nature of your task, models like CNN or LSTM could perform well. TensorFlow/Keras will be used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An initial simple Binary logistic  regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "\n",
    "    # Initialize the Logistic Regression model\n",
    "    model = LogisticRegression(max_iter=1000)  # Increasing max_iter for convergence\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Return the trained model\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not using the NN below yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X_train, y_train, X_test, y_test):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=64))  # Adjust according to the TF-IDF feature size\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(3, activation='softmax'))  # Three categories\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Classification of New Documents --- not ready:\n",
    "- **Predicting Categories:** Use the trained model to predict categories for new documents after preprocessing and vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text):\n",
    "    clean_text = clean_and_tokenize(text)\n",
    "    vectorized_text = vectorizer.transform([clean_text])\n",
    "    prediction = model.predict(vectorized_text)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation and Iteration not ready\n",
    "\n",
    "- **Evaluation:** Use metrics like accuracy, precision, recall, and F1 score to evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Iteration:** Based on evaluation results, iterate over your model by tuning hyperparameters, trying different models (e.g., BERT for text classification), or using more advanced text vectorization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Scalability and Optimization\n",
    "\n",
    "- Consider parallel processing or distributed computing for preprocessing steps if you face performance bottlenecks.\n",
    "- Explore incremental learning or online learning models if retraining on new data frequently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/uw/invest-data/classify_presentations/data/dataset.csv'\n",
    "DATA_PATH = \"/dave/presentations/\"\n",
    "os.path.exists(dataset_path)\n",
    "df = pd.read_csv(dataset_path, header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['fname'] = DATA_PATH + df['fname']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: syntax error: syntax error in array\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in array\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in array\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-a'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '0.3d'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-11cv6e35cI'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: 't.1'\n",
      "MuPDF error: syntax error: unknown keyword: '10e4'\n",
      "MuPDF error: syntax error: unknown keyword: '2s'\n",
      "MuPDF error: syntax error: unknown keyword: 'th66.5'\n",
      "MuPDF error: syntax error: unknown keyword: '10.t'\n",
      "MuPDF error: syntax error: unknown keyword: 'sa'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-9.1of'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '10e'\n",
      "MuPDF error: syntax error: unknown keyword: 'th66-11cv6e35110e4'\n",
      "MuPDF error: syntax error: unknown keyword: 'bas'\n",
      "MuPDF error: syntax error: unknown keyword: 'th66i'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '52s'\n",
      "MuPDF error: syntax error: unknown keyword: 'th66.-11cv6es'\n",
      "MuPDF error: syntax error: unknown keyword: 'th66.-'\n",
      "MuPDF error: syntax error: unknown keyword: 'be'\n",
      "MuPDF error: syntax error: unknown keyword: '1f'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-11rei'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '52g8'\n",
      "MuPDF error: syntax error: unknown keyword: '-11n'\n",
      "MuPDF error: syntax error: unknown keyword: 'of'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-7.2'\n",
      "MuPDF error: syntax error: unknown keyword: '10.ac.2'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '41n'\n",
      "MuPDF error: syntax error: unknown keyword: 'of'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '10.i'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '52s'\n",
      "MuPDF error: syntax error: unknown keyword: 'th66.br'\n",
      "MuPDF error: syntax error: unknown keyword: '10g.1of'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '10.2'\n",
      "MuPDF error: syntax error: unknown keyword: '10.In'\n",
      "MuPDF error: syntax error: unknown keyword: 'of'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '10di'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '10..2'\n",
      "MuPDF error: syntax error: unknown keyword: 'of'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '10e4'\n",
      "MuPDF error: syntax error: unknown keyword: '2r35110ore,.i'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '52.2'\n",
      "MuPDF error: syntax error: unknown keyword: '20g'\n",
      "MuPDF error: syntax error: unknown keyword: 'to'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '20m'\n",
      "MuPDF error: syntax error: unknown keyword: 'th11e2'\n",
      "MuPDF error: syntax error: unknown keyword: '20r8'\n",
      "MuPDF error: syntax error: unknown keyword: '53e6'\n",
      "MuPDF error: syntax error: unknown keyword: '-7n1'\n",
      "MuPDF error: syntax error: unknown keyword: 'c.4'\n",
      "MuPDF error: syntax error: unknown keyword: '8r8'\n",
      "MuPDF error: syntax error: unknown keyword: '53r8'\n",
      "MuPDF error: syntax error: unknown keyword: '53e6'\n",
      "MuPDF error: syntax error: unknown keyword: 'on'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '101sudgm'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '82r5'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in array\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-10.3s'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '11318.1to'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '19..3'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '0.7nsi2.89'\n",
      "MuPDF error: syntax error: unknown keyword: '-t'\n",
      "MuPDF error: syntax error: unknown keyword: 'ra-2.89'\n",
      "MuPDF error: syntax error: unknown keyword: '-1.th'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '82eteo'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '19.4bd'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '82el'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '82et0.0018'\n",
      "MuPDF error: syntax error: unknown keyword: 'T0.9'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '1accoun'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: 'a10.9'\n",
      "MuPDF error: syntax error: unknown keyword: ','\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '19.4w'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '6s7ehw0.'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-n'\n",
      "MuPDF error: syntax error: unknown keyword: 'it'\n",
      "MuPDF error: syntax error: unknown keyword: 'isdim'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '8.r'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: 'srev'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '12.9or'\n",
      "MuPDF error: syntax error: unknown keyword: 't'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '13oteo0.783y'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-40r'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: 'IT9-C'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-40r'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: 'IT9-av'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '210r'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '6ns'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '71re'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-103.eeca'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-10.3s'\n",
      "MuPDF error: syntax error: unknown keyword: 'v0.5'\n",
      "MuPDF error: syntax error: unknown keyword: '-103.eelo0.783ya'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-2118.l'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: 'e1'\n",
      "MuPDF error: syntax error: unknown keyword: '118.s�s'\n",
      "MuPDF error: syntax error: unknown keyword: 'e4'\n",
      "MuPDF error: syntax error: unknown keyword: '118.t'\n",
      "MuPDF error: syntax error: unknown keyword: 'e3yd'\n",
      "MuPDF error: syntax error: unknown keyword: 'i19.9'\n",
      "MuPDF error: syntax error: unknown keyword: '71uco'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: '-0e.1ae10.33d'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: 'nd'\n",
      "MuPDF error: syntax error: unknown keyword: 'se-2.5.5cur'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: unknown keyword: 'e'\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: syntax error: syntax error in content stream\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n",
      "MuPDF error: format error: No default Layer config\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_text'] = df['fname'].apply(pdf_to_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1000/1000 [44:02<00:00,  2.64s/it] \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Processing documents\")\n",
    "\n",
    "df['tokenized_text'] = df['cleaned_text'].progress_apply(clean_and_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {\n",
    "    \"financial_terms\": ['financial', 'investment', 'share price', 'financial metrics', 'investment strategy'],\n",
    "    \"legal_statements\": ['confidentiality statement', 'legal disclaimer', 'disclosure statement', 'proprietary information', 'intellectual property'],\n",
    "    \"company_info\": ['company overview', 'company analysis', 'business model', 'company performance'],\n",
    "    \"presentation_content\": ['visual aids', 'data charts', 'case studies', 'comparative analysis'],\n",
    "    \"company_targets\": ['sales targets', 'company targets', 'performance targets'],\n",
    "    \"financial_discussions\": ['financial figures', 'financial projections', 'financial results', 'financial language'],\n",
    "    \"regulatory_references\": ['SEC filings', 'regulatory filings', 'external entities', 'lawsuits'],\n",
    "    \"detail_descriptions\": ['loan details', 'product details', 'research and development', 'financial details'],\n",
    "    \"company_specific\": ['company specific', 'industry specific', 'company-specific analysis', 'specific company focus']\n",
    "    # \"Other Clusters\" category is omitted since it's broad and without specific keywords\n",
    "}\n",
    "\n",
    "\n",
    "# Apply keyword matching\n",
    "for category, keyword_list in keywords.items():\n",
    "    df[category + '_keyword'] = df['tokenized_text'].apply(check_keywords, args=(keyword_list,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = combine_tfidf_keyword(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(features, df['presentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8766666666666667\n",
      "Precision: 0.9583333333333334\n",
      "Recall: 0.5679012345679012\n",
      "F1 Score: 0.7131782945736435\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate and print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='binary'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='binary'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='binary'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, pandas.core.series.Series)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame `df_test` corresponding to your test dataset\n",
    "# And it includes a column 'doc_id' or similar that uniquely identifies each document\n",
    "# If you don't have such a DataFrame, you can create it from `X_test` and `y_test`\n",
    "\n",
    "\n",
    "type(X_test), type(y_test)\n",
    "# df_test = pd.DataFrame({'doc_id': X_test.index, 'text': X_test, 'label': y_test})\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, ensure `X_test` retains its index after splitting so you can merge based on index\n",
    "misclassified_df = pd.DataFrame({\n",
    "    'True Label': y_test,\n",
    "    'Predicted Label': y_pred\n",
    "})\n",
    "\n",
    "# If `X_test` and `y_test` don't automatically align, you might need to reset the index\n",
    "# misclassified_df = misclassified_df.reset_index()\n",
    "\n",
    "# Add a column to indicate whether each prediction is correct\n",
    "misclassified_df['Correctly Classified'] = misclassified_df['True Label'] == misclassified_df['Predicted Label']\n",
    "\n",
    "# Filter the DataFrame to only include misclassified documents\n",
    "misclassified_docs = misclassified_df[~misclassified_df['Correctly Classified']]\n",
    "\n",
    "# Optionally, join with the original DataFrame (df) to include text or other identifying information\n",
    "# This step requires that `df` and `misclassified_docs` can be aligned by index or a unique identifier\n",
    "# Example:\n",
    "# misclassified_docs = misclassified_docs.join(df[['doc_id', 'text']], how='left')\n",
    "\n",
    "misclassified_docs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchnames",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
